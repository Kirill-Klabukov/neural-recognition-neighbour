{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88e8e788",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Starts\n",
      "Epoch Starts\n",
      "Epoch : 1, train accuracy : 0.47805556654930115, train loss : 1.2247724533081055\n",
      "Epoch : 1, val_accuracy : 0.5994117856025696, val_loss : 1.0529590845108032\n",
      "Accuracy of the network on the 10000 test images: 59.94117736816406 %\n",
      "Progress Saved\n",
      "Epoch Starts\n",
      "Epoch : 2, train accuracy : 0.5464583039283752, train loss : 1.0777558088302612\n",
      "Epoch : 2, val_accuracy : 0.6682353019714355, val_loss : 0.9708294868469238\n",
      "Accuracy of the network on the 10000 test images: 66.82353210449219 %\n",
      "Progress Saved\n",
      "Epoch Starts\n",
      "Epoch : 3, train accuracy : 0.5850000381469727, train loss : 0.9715657234191895\n",
      "Epoch : 3, val_accuracy : 0.619411826133728, val_loss : 0.8208858966827393\n",
      "Accuracy of the network on the 10000 test images: 61.94118118286133 %\n",
      "Epoch Starts\n",
      "Epoch : 4, train accuracy : 0.6094443798065186, train loss : 0.9153999090194702\n",
      "Epoch : 4, val_accuracy : 0.6201961040496826, val_loss : 0.8576059341430664\n",
      "Accuracy of the network on the 10000 test images: 62.01961135864258 %\n",
      "Epoch Starts\n",
      "Epoch : 5, train accuracy : 0.65645831823349, train loss : 0.8578777313232422\n",
      "Epoch : 5, val_accuracy : 0.6856862902641296, val_loss : 0.7694717645645142\n",
      "Accuracy of the network on the 10000 test images: 68.5686264038086 %\n",
      "Progress Saved\n",
      "Epoch Starts\n",
      "Epoch : 6, train accuracy : 0.6531250476837158, train loss : 0.8319605588912964\n",
      "Epoch : 6, val_accuracy : 0.6590195894241333, val_loss : 0.7656328082084656\n",
      "Accuracy of the network on the 10000 test images: 65.90196228027344 %\n",
      "Epoch Starts\n",
      "Epoch : 7, train accuracy : 0.661666750907898, train loss : 0.8237709999084473\n",
      "Epoch : 7, val_accuracy : 0.6198039054870605, val_loss : 0.9137938618659973\n",
      "Accuracy of the network on the 10000 test images: 61.98039245605469 %\n",
      "Epoch Starts\n",
      "Epoch : 8, train accuracy : 0.6689583659172058, train loss : 0.7714929580688477\n",
      "Epoch : 8, val_accuracy : 0.6368627548217773, val_loss : 0.8265043497085571\n",
      "Accuracy of the network on the 10000 test images: 63.686275482177734 %\n",
      "Epoch Starts\n",
      "Epoch : 9, train accuracy : 0.7088888883590698, train loss : 0.714424729347229\n",
      "Epoch : 9, val_accuracy : 0.6923529505729675, val_loss : 0.6506006717681885\n",
      "Accuracy of the network on the 10000 test images: 69.23529815673828 %\n",
      "Progress Saved\n",
      "Epoch Starts\n",
      "Epoch : 10, train accuracy : 0.716041624546051, train loss : 0.6929160952568054\n",
      "Epoch : 10, val_accuracy : 0.7649019956588745, val_loss : 0.6701574325561523\n",
      "Accuracy of the network on the 10000 test images: 76.49019622802734 %\n",
      "Progress Saved\n",
      "Epoch Starts\n",
      "Epoch : 11, train accuracy : 0.7213194966316223, train loss : 0.6746714115142822\n",
      "Epoch : 11, val_accuracy : 0.7127450704574585, val_loss : 0.696993350982666\n",
      "Accuracy of the network on the 10000 test images: 71.27450561523438 %\n",
      "Epoch Starts\n",
      "Epoch : 12, train accuracy : 0.730138897895813, train loss : 0.6281653046607971\n",
      "Epoch : 12, val_accuracy : 0.7582353353500366, val_loss : 0.5960444808006287\n",
      "Accuracy of the network on the 10000 test images: 75.82353210449219 %\n",
      "Epoch Starts\n",
      "Epoch : 13, train accuracy : 0.73395836353302, train loss : 0.6911874413490295\n",
      "Epoch : 13, val_accuracy : 0.7056863307952881, val_loss : 0.6845089197158813\n",
      "Accuracy of the network on the 10000 test images: 70.56863403320312 %\n",
      "Epoch Starts\n",
      "Epoch : 14, train accuracy : 0.7377777695655823, train loss : 0.6458890438079834\n",
      "Epoch : 14, val_accuracy : 0.8078430891036987, val_loss : 0.6572983264923096\n",
      "Accuracy of the network on the 10000 test images: 80.78430938720703 %\n",
      "Progress Saved\n",
      "Epoch Starts\n",
      "Epoch : 15, train accuracy : 0.747708261013031, train loss : 0.6568466424942017\n",
      "Epoch : 15, val_accuracy : 0.8370587825775146, val_loss : 0.48207855224609375\n",
      "Accuracy of the network on the 10000 test images: 83.70587921142578 %\n",
      "Progress Saved\n",
      "Epoch Starts\n",
      "Epoch : 16, train accuracy : 0.7677777409553528, train loss : 0.6007073521614075\n",
      "Epoch : 16, val_accuracy : 0.7749019861221313, val_loss : 0.5629552602767944\n",
      "Accuracy of the network on the 10000 test images: 77.49019622802734 %\n",
      "Epoch Starts\n",
      "Epoch : 17, train accuracy : 0.7879167199134827, train loss : 0.5842814445495605\n",
      "Epoch : 17, val_accuracy : 0.7941176891326904, val_loss : 0.5331238508224487\n",
      "Accuracy of the network on the 10000 test images: 79.4117660522461 %\n",
      "Epoch Starts\n",
      "Epoch : 18, train accuracy : 0.7740278244018555, train loss : 0.5733322501182556\n",
      "Epoch : 18, val_accuracy : 0.8011764287948608, val_loss : 0.5292210578918457\n",
      "Accuracy of the network on the 10000 test images: 80.11764526367188 %\n",
      "Epoch Starts\n",
      "Epoch : 19, train accuracy : 0.7769444584846497, train loss : 0.5393216013908386\n",
      "Epoch : 19, val_accuracy : 0.7352941036224365, val_loss : 0.6583073735237122\n",
      "Accuracy of the network on the 10000 test images: 73.52941131591797 %\n",
      "Epoch Starts\n",
      "Epoch : 20, train accuracy : 0.7990278601646423, train loss : 0.5092605352401733\n",
      "Epoch : 20, val_accuracy : 0.7882353067398071, val_loss : 0.5476871728897095\n",
      "Accuracy of the network on the 10000 test images: 78.82353210449219 %\n",
      "Epoch Starts\n",
      "Epoch : 21, train accuracy : 0.7712500095367432, train loss : 0.5818701982498169\n",
      "Epoch : 21, val_accuracy : 0.7452940940856934, val_loss : 0.5749766826629639\n",
      "Accuracy of the network on the 10000 test images: 74.52941131591797 %\n",
      "Epoch Starts\n",
      "Epoch : 22, train accuracy : 0.7901389002799988, train loss : 0.552966296672821\n",
      "Epoch : 22, val_accuracy : 0.8049019575119019, val_loss : 0.47752249240875244\n",
      "Accuracy of the network on the 10000 test images: 80.49019622802734 %\n",
      "Epoch Starts\n",
      "Epoch : 23, train accuracy : 0.8060415983200073, train loss : 0.5083065032958984\n",
      "Epoch : 23, val_accuracy : 0.827843189239502, val_loss : 0.5179409384727478\n",
      "Accuracy of the network on the 10000 test images: 82.78431701660156 %\n",
      "Epoch Starts\n",
      "Epoch : 24, train accuracy : 0.7920138835906982, train loss : 0.5235887169837952\n",
      "Epoch : 24, val_accuracy : 0.7782353162765503, val_loss : 0.6477842330932617\n",
      "Accuracy of the network on the 10000 test images: 77.82353210449219 %\n",
      "Epoch Starts\n",
      "Epoch : 25, train accuracy : 0.7963194251060486, train loss : 0.5132272243499756\n",
      "Epoch : 25, val_accuracy : 0.7615686655044556, val_loss : 0.5257959365844727\n",
      "Accuracy of the network on the 10000 test images: 76.15686798095703 %\n",
      "Epoch Starts\n",
      "Epoch : 26, train accuracy : 0.7713889479637146, train loss : 0.5546410083770752\n",
      "Epoch : 26, val_accuracy : 0.7849019765853882, val_loss : 0.5876697897911072\n",
      "Accuracy of the network on the 10000 test images: 78.49019622802734 %\n",
      "Epoch Starts\n",
      "Epoch : 27, train accuracy : 0.801111102104187, train loss : 0.5245715379714966\n",
      "Epoch : 27, val_accuracy : 0.7298039197921753, val_loss : 0.6629824638366699\n",
      "Accuracy of the network on the 10000 test images: 72.98039245605469 %\n",
      "Epoch Starts\n",
      "Epoch : 28, train accuracy : 0.7968055605888367, train loss : 0.5186320543289185\n",
      "Epoch : 28, val_accuracy : 0.7615686655044556, val_loss : 0.5418568849563599\n",
      "Accuracy of the network on the 10000 test images: 76.15686798095703 %\n",
      "Epoch Starts\n",
      "Epoch : 29, train accuracy : 0.7918750047683716, train loss : 0.5641967058181763\n",
      "Epoch : 29, val_accuracy : 0.817058801651001, val_loss : 0.49887615442276\n",
      "Accuracy of the network on the 10000 test images: 81.70587921142578 %\n",
      "Epoch Starts\n",
      "Epoch : 30, train accuracy : 0.8140972852706909, train loss : 0.48483163118362427\n",
      "Epoch : 30, val_accuracy : 0.7719607353210449, val_loss : 0.6209754943847656\n",
      "Accuracy of the network on the 10000 test images: 77.19607543945312 %\n",
      "Epoch Starts\n",
      "Epoch : 31, train accuracy : 0.8163195252418518, train loss : 0.5088087916374207\n",
      "Epoch : 31, val_accuracy : 0.824509859085083, val_loss : 0.4744148254394531\n",
      "Accuracy of the network on the 10000 test images: 82.45098876953125 %\n",
      "Epoch Starts\n",
      "Epoch : 32, train accuracy : 0.7982639074325562, train loss : 0.543802797794342\n",
      "Epoch : 32, val_accuracy : 0.8700000047683716, val_loss : 0.4183962345123291\n",
      "Accuracy of the network on the 10000 test images: 87.0 %\n",
      "Progress Saved\n",
      "Epoch Starts\n",
      "Epoch : 33, train accuracy : 0.7902777791023254, train loss : 0.5257163643836975\n",
      "Epoch : 33, val_accuracy : 0.7619607448577881, val_loss : 0.6287740468978882\n",
      "Accuracy of the network on the 10000 test images: 76.19607543945312 %\n",
      "Epoch Starts\n",
      "Epoch : 34, train accuracy : 0.8120139241218567, train loss : 0.4872853457927704\n",
      "Epoch : 34, val_accuracy : 0.8445098400115967, val_loss : 0.43068957328796387\n",
      "Accuracy of the network on the 10000 test images: 84.45098114013672 %\n",
      "Epoch Starts\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 35, train accuracy : 0.8184027671813965, train loss : 0.45894116163253784\n",
      "Epoch : 35, val_accuracy : 0.8149019479751587, val_loss : 0.5117992758750916\n",
      "Accuracy of the network on the 10000 test images: 81.49019622802734 %\n",
      "Epoch Starts\n",
      "Epoch : 36, train accuracy : 0.7804861068725586, train loss : 0.538226306438446\n",
      "Epoch : 36, val_accuracy : 0.7978430986404419, val_loss : 0.4646163284778595\n",
      "Accuracy of the network on the 10000 test images: 79.78430938720703 %\n",
      "Epoch Starts\n",
      "Epoch : 37, train accuracy : 0.7961804866790771, train loss : 0.4957093298435211\n",
      "Epoch : 37, val_accuracy : 0.8078430891036987, val_loss : 0.4187275171279907\n",
      "Accuracy of the network on the 10000 test images: 80.78430938720703 %\n",
      "Epoch Starts\n",
      "Epoch : 38, train accuracy : 0.8020139336585999, train loss : 0.48182961344718933\n",
      "Epoch : 38, val_accuracy : 0.824509859085083, val_loss : 0.5470873117446899\n",
      "Accuracy of the network on the 10000 test images: 82.45098876953125 %\n",
      "Epoch Starts\n",
      "Epoch : 39, train accuracy : 0.8388194441795349, train loss : 0.4352145195007324\n",
      "Epoch : 39, val_accuracy : 0.7782353162765503, val_loss : 0.4584805369377136\n",
      "Accuracy of the network on the 10000 test images: 77.82353210449219 %\n",
      "Epoch Starts\n",
      "Epoch : 40, train accuracy : 0.8049999475479126, train loss : 0.4912702441215515\n",
      "Epoch : 40, val_accuracy : 0.820784330368042, val_loss : 0.4284144341945648\n",
      "Accuracy of the network on the 10000 test images: 82.07843017578125 %\n",
      "Epoch Starts\n",
      "Epoch : 41, train accuracy : 0.8220139145851135, train loss : 0.4548782706260681\n",
      "Epoch : 41, val_accuracy : 0.768627405166626, val_loss : 0.5144147872924805\n",
      "Accuracy of the network on the 10000 test images: 76.86273956298828 %\n",
      "Epoch Starts\n",
      "Epoch : 42, train accuracy : 0.8165971636772156, train loss : 0.47849780321121216\n",
      "Epoch : 42, val_accuracy : 0.8341176509857178, val_loss : 0.47159335017204285\n",
      "Accuracy of the network on the 10000 test images: 83.4117660522461 %\n",
      "Epoch Starts\n",
      "Epoch : 43, train accuracy : 0.8150694370269775, train loss : 0.48729345202445984\n",
      "Epoch : 43, val_accuracy : 0.8274509906768799, val_loss : 0.49357447028160095\n",
      "Accuracy of the network on the 10000 test images: 82.74510192871094 %\n",
      "Epoch Starts\n",
      "Epoch : 44, train accuracy : 0.8359723091125488, train loss : 0.44022446870803833\n",
      "Epoch : 44, val_accuracy : 0.8541176319122314, val_loss : 0.34819716215133667\n",
      "Accuracy of the network on the 10000 test images: 85.4117660522461 %\n",
      "Epoch Starts\n",
      "Epoch : 45, train accuracy : 0.8307638764381409, train loss : 0.444896936416626\n",
      "Epoch : 45, val_accuracy : 0.7923530340194702, val_loss : 0.4524809718132019\n",
      "Accuracy of the network on the 10000 test images: 79.23530578613281 %\n",
      "Epoch Starts\n"
     ]
    }
   ],
   "source": [
    "#about torch...\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torchvision import datasets, models, transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "#using numpy\n",
    "import numpy as np\n",
    "\n",
    "#for data load or save\n",
    "import pandas as pd\n",
    "\n",
    "#visualize some datasets\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#check our work directory\n",
    "import os\n",
    "\n",
    "\n",
    "\n",
    "lr = 0.001 # learning_rate\n",
    "batch_size = 100 # we will use mini-batch method\n",
    "epochs = 200 # How much to train a model\n",
    "train = True\n",
    "\n",
    "# os.listdir('data/train')\n",
    "\n",
    "device = 'cuda' \n",
    "\n",
    "torch.manual_seed(1234)\n",
    "if device == 'cuda':\n",
    "    torch.manual_seed(1234)\n",
    "    # torch.mps.manual_seed_all(1234)\n",
    "    # os.makedirs('data/catORdog', exist_ok=True)\n",
    "    base_dir = 'archive'\n",
    "    train_dir = 'archive/seg_train'\n",
    "    test_dir = 'archive/seg_pred'\n",
    "    train_list = []\n",
    "    test_list = []\n",
    "    from pathlib import Path\n",
    "    for path in Path(train_dir).rglob('*.jpg'):\n",
    "        train_list.append(path)\n",
    "    for path in Path(test_dir).rglob('*.jpg'):\n",
    "        test_list.append(path)\n",
    "\n",
    "    from PIL import Image\n",
    "\n",
    "    random_idx = np.random.randint(1, 12000, size=10)\n",
    "\n",
    "\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    train_list, val_list = train_test_split(train_list, test_size=0.2)\n",
    "\n",
    "    # data Augumentation\n",
    "    train_transforms = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "    ])\n",
    "\n",
    "    val_transforms = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "    ])\n",
    "\n",
    "    test_transforms = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    "\n",
    "\n",
    "    class dataset(torch.utils.data.Dataset):\n",
    "\n",
    "        def __init__(self, file_list, transform=None):\n",
    "            self.file_list = file_list\n",
    "            self.transform = transform\n",
    "\n",
    "        # dataset length\n",
    "        def __len__(self):\n",
    "            self.filelength = len(self.file_list)\n",
    "            return self.filelength\n",
    "\n",
    "        # load an one of images\n",
    "        def __getitem__(self, idx):\n",
    "            img_path = self.file_list[idx]\n",
    "            img = Image.open(img_path)\n",
    "            img_transformed = self.transform(img)\n",
    "            \n",
    "            label = img_path.parts\n",
    "            if img_path.parts[1] == 'seg_train':\n",
    "                if label[2] == 'kirill':\n",
    "                    label = 0\n",
    "                elif label[2] == 'oleg':\n",
    "                    label = 1\n",
    "                elif label[2] == 'vlad':\n",
    "                    label = 2\n",
    "                elif label[2] == 'roma':\n",
    "                    label = 3\n",
    "               \n",
    "            else:\n",
    "                \n",
    "                label = label[2].split('.')[0]+'.'+label[2].split('.')[1]\n",
    "            return img_transformed, label\n",
    "\n",
    "\n",
    "    train_data = dataset(train_list, transform=train_transforms)\n",
    "    test_data = dataset(test_list, transform=test_transforms)\n",
    "    val_data = dataset(val_list, transform=test_transforms)\n",
    "    \n",
    "    train_loader = torch.utils.data.DataLoader(dataset=train_data, batch_size=batch_size, shuffle=True)\n",
    "    test_loader = torch.utils.data.DataLoader(dataset=test_data, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = torch.utils.data.DataLoader(dataset=val_data, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "\n",
    "    class Cnn(nn.Module):\n",
    "        def __init__(self):\n",
    "            super(Cnn, self).__init__()\n",
    "\n",
    "            self.layer1 = nn.Sequential(\n",
    "                nn.Conv2d(3, 16, kernel_size=3, padding=0, stride=2),\n",
    "                nn.BatchNorm2d(16),\n",
    "                nn.ReLU(),\n",
    "                nn.MaxPool2d(2)\n",
    "            )\n",
    "\n",
    "            self.layer2 = nn.Sequential(\n",
    "                nn.Conv2d(16, 32, kernel_size=3, padding=0, stride=2),\n",
    "                nn.BatchNorm2d(32),\n",
    "                nn.ReLU(),\n",
    "                nn.MaxPool2d(2)\n",
    "            )\n",
    "\n",
    "            self.layer3 = nn.Sequential(\n",
    "                nn.Conv2d(32, 64, kernel_size=3, padding=0, stride=2),\n",
    "                nn.BatchNorm2d(64),\n",
    "                nn.ReLU(),\n",
    "                nn.MaxPool2d(2)\n",
    "            )\n",
    "\n",
    "            self.fc1 = nn.Linear(3 * 3 * 64, 254)\n",
    "            self.dropout = nn.Dropout(0.5)\n",
    "            self.fc2 = nn.Linear(254, 120)\n",
    "            self.fc3 = nn.Linear(120, 80)\n",
    "            self.fc4 = nn.Linear(80, 40)\n",
    "            self.fc5 = nn.Linear(40, 4)\n",
    "            \n",
    "            \n",
    "\n",
    "        def forward(self, x):\n",
    "            out = self.layer1(x)\n",
    "            out = self.layer2(out)\n",
    "            out = self.layer3(out)\n",
    "            out = out.view(out.size(0), -1)\n",
    "            out = self.fc1(out)\n",
    "            out = self.fc2(out)\n",
    "            out = self.fc3(out)\n",
    "            out = self.fc4(out)\n",
    "            out = self.fc5(out)\n",
    "            return out\n",
    "\n",
    "\n",
    "    model = Cnn().to(device)\n",
    "    if os.path.isfile(\"CNNmodel.pt\"):\n",
    "        model.load_state_dict(torch.load('CNNmodel.pt'))\n",
    "    model.train()\n",
    "\n",
    "    optimizer = optim.Adam(params=model.parameters(), lr=0.001)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    \n",
    "    lastAccuracy = 0\n",
    "    nowAccuracy = 0\n",
    "    if train == True :\n",
    "        print(\"Train Starts\")\n",
    "        for epoch in range(epochs):\n",
    "            print(\"Epoch Starts\")\n",
    "            epoch_loss = 0\n",
    "            epoch_accuracy = 0\n",
    "        \n",
    "\n",
    "            # if os.path.isfile(\"CNNmodel.pt\"):\n",
    "            #     model.load_state_dict(torch.load('CNNmodel.pt'))\n",
    "            for data, label in train_loader:\n",
    "                data = data.to(device)\n",
    "                \n",
    "                label = label.to(device)\n",
    "                \n",
    "\n",
    "                output = model(data)\n",
    "                \n",
    "                loss = criterion(output, label)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                acc = ((output.argmax(dim=1) == label).float().mean())\n",
    "                epoch_accuracy += acc / len(train_loader)\n",
    "                epoch_loss += loss / len(train_loader)\n",
    "\n",
    "            print('Epoch : {}, train accuracy : {}, train loss : {}'.format(epoch + 1, epoch_accuracy, epoch_loss))\n",
    "\n",
    "            with torch.no_grad():\n",
    "                epoch_val_accuracy = 0\n",
    "                epoch_val_loss = 0\n",
    "                for data, label in val_loader:\n",
    "                    data = data.to(device)\n",
    "                \n",
    "                    label = label.to(device)\n",
    "\n",
    "                    val_output = model(data)\n",
    "                    val_loss = criterion(val_output, label)\n",
    "\n",
    "                    acc = ((val_output.argmax(dim=1) == label).float().mean())\n",
    "                    epoch_val_accuracy += acc / len(val_loader)\n",
    "                    epoch_val_loss += val_loss / len(val_loader)\n",
    "                nowAccuracy = 100 * epoch_val_accuracy   \n",
    "                print('Epoch : {}, val_accuracy : {}, val_loss : {}'.format(epoch + 1, epoch_val_accuracy, epoch_val_loss))\n",
    "                print(f'Accuracy of the network on the 10000 test images: {100 * epoch_val_accuracy} %')\n",
    "            if(nowAccuracy > lastAccuracy):\n",
    "                torch.save(model.state_dict(), 'CNNmodel.pt')\n",
    "                print(\"Progress Saved\")\n",
    "                lastAccuracy = nowAccuracy\n",
    "    \n",
    "\n",
    "    if train == False:\n",
    "        class_ = {0: 'kirill', 1: 'oleg', 2: 'vlad', 3: 'roma'}\n",
    "        results = []\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for data, fileid in test_loader:\n",
    "                data = data.to(device)\n",
    "                preds = model(data)\n",
    "                \n",
    "                _, preds = torch.max(preds, dim=1)\n",
    "                \n",
    "                results += list(zip(list(fileid), preds.tolist()))\n",
    "                \n",
    "\n",
    "       \n",
    "       \n",
    "       \n",
    "        idx = list(map(lambda x: x[0], results))\n",
    "        prob = list(map(lambda x: x[1], results))\n",
    "\n",
    "        submission = pd.DataFrame({'id': idx, 'label': prob})\n",
    "        \n",
    "        \n",
    "\n",
    "        import random\n",
    "\n",
    "        id_list = []\n",
    "        \n",
    "        \n",
    "        fig, axes = plt.subplots(2, 5, figsize=(5, 5), facecolor='w')\n",
    "       \n",
    "\n",
    "        for ax in axes.ravel():\n",
    "\n",
    "            i = random.choice(submission['id'].values)\n",
    "           \n",
    "            label = submission.loc[submission['id'] == i, 'label'].values[0]\n",
    "            \n",
    "            \n",
    "\n",
    "            img_path = os.path.join(test_dir, '{}.jpg'.format(i))\n",
    "            img = Image.open(img_path)\n",
    "            img = img.resize((224, 224))\n",
    "            ax.set_title(class_[label])\n",
    "            ax.axis('off')\n",
    "            ax.imshow(img)\n",
    "           \n",
    "        \n",
    "        plt.show()\n",
    "    \n",
    "       \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5ef595f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
